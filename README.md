# GHCN-Data-Analysis-Using-Spark
We will study and use Spark to explore and analyze the weather data included in the Global Historical Climate Network (GHCN).
GHCN is a comprehensive database containing daily climate summaries from surface weather stations worldwide. It consists of daily climate records from multiple sources consolidated and subject to a standard set of quality assurance reviews (refer from NCEI-GHCN). This database includes papers from 118493 sites in 219 countries and territories covering the last 175 years and is from over 20 independent sources (Menne,2012). It provides several daily variables, including maximum and minimum temperatures, total daily precipitation, snowfall and snow depth. Around half of all-weather stations report only rain. The length and period of records vary from station to station, with coverage intervals ranging from less than one year to 175 years.
Spark as a tool is to run distributing computations over the large data sets. Pyspark is an interface for Apache Spark in Python. It can provide Spark application using Python APIs with users to write and contains the shell for interactively analysing data in a distributed environment. This report will apply some of Sparkâ€™s features like Spark SQL, Data Frame, Machine Learning, and Spark Core for further analysing of these target data. Also, we will use the plotting method to present the time series for TMIN and TMAX for each station in New Zealand and the average rainfall distribution in 2021 for each country. 
